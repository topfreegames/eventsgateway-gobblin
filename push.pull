job.name=pushes
job.group=pushes
job.description=pushes
job.lock.enabled=true
job.schedule=0 0/10 * * * ?

kafka.brokers=${env:KAFKA_BROKERS}
kafka.workunit.packer.type=BI_LEVEL

source.class=gobblin.source.extractor.extract.kafka.KafkaSimpleSource
extract.namespace=gobblin.extract.kafka
extract.limit.enabled=true
extract.limit.type=time
extract.limit.timeLimit=120
extract.limit.timeLimitTimeunit=minutes

converter.classes=com.tfgco.push.gobblin.PushNotificationBytesToAvroConverter

writer.partitioner.class=com.tfgco.eventsgateway.gobblin.GobblinDailyPartitioner
writer.partition.pattern=YYYY/MM/dd
writer.partition.columns=timestamp
writer.builder.class=gobblin.writer.AvroDataWriterBuilder
writer.file.path.type=tablename
writer.partition.timezone=UTC
writer.destination.type=HDFS
writer.output.format=AVRO

writer.codec.type=SNAPPY
writer.deflate.level=6
writer.include.partition.in.file.names=false

mr.job.max.mappers=5

topic.whitelist=^push-.*-(single|massive)$
data.publisher.type=gobblin.publisher.TimePartitionedDataPublisher

metrics.reporting.file.enabled=true
metrics.log.dir=${env:GOBBLIN_WORK_DIR}/metrics
metrics.reporting.file.suffix=txt
